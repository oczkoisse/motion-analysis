{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Returns a copy of data which is normalized around mean of spinal base point\n",
    "def normalize_spine_base(data):\n",
    "    b = np.copy(data)\n",
    "    spine = np.zeros(3)\n",
    "    for i in range(3):\n",
    "       spine[i] = np.mean(b[:, i])\n",
    "    m, n = b.shape\n",
    "    for i in range(n):\n",
    "       b[:, i] -= spine[i % 3]\n",
    "    return b\n",
    "\n",
    "# Pulls up torso skeleton data from a general skeleton file, and normalizes it using normalize_spine_data()\n",
    "def load_skeleton_data(filename):\n",
    "    data = np.loadtxt(filename, dtype='float', delimiter=',', skiprows=1, usecols=(9, 10, 11, 18, 19, 20, 27, 28, 29, 36, 37, 38, 45, 46, 47, 54, 55, 56, 63, 64, 65, 72, 73, 74, 81, 82, 83, 90, 91, 92, 99, 100, 101, 108, 109, 110, 189, 190, 191))\n",
    "    return normalize_spine_base(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "from pathlib import Path\n",
    "\n",
    "# Chosse a random skeleton file for a given gesture\n",
    "def choose_random_skeleton(gesture):\n",
    "    current_dir = Path('.')\n",
    "    data_dir = current_dir / 'data' / gesture\n",
    "    return random.choice([str(f) for f in list(data_dir.glob(\"*.txt\")) if f.is_file()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of samples to be taken from each gesture class\n",
    "tot_samples = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taking tot_samples number of samples from both gesture classes\n",
    "x_files = [ choose_random_skeleton('head_nod') for i in range(tot_samples) ]\n",
    "y_files = [ choose_random_skeleton('arms_move_down') for i in range(tot_samples) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples chosen:\n",
      "\n",
      "data\\head_nod\\Gesture52_Session 20-Participant 39-Block 7_118670000_Skeleton.txt\n",
      "data\\head_nod\\Gesture52_Session 20-Participant 40-Block 1_1220811621_Skeleton.txt\n",
      "data\\head_nod\\Gesture52_Session 18-Participant 36-Block 4_271330000_Skeleton.txt\n",
      "data\\arms_move_down\\Gesture968_Session 16-Participant 32-Block 3_1437000000_Skeleton.txt\n",
      "data\\arms_move_down\\Gesture968_Session 6-Participant 12-Block 3_56330000_Skeleton.txt\n",
      "data\\arms_move_down\\Gesture968_Session 3-Participant 5-Block 8_827038820_Skeleton.txt\n",
      "\n",
      "Similarity matrix is:\n",
      "\n",
      "[[ 0.          0.40058228  0.49669788  0.63684059  0.56747494  0.49062729]\n",
      " [ 0.40058228  0.          0.32842351  0.65249574  0.28888665  0.38517657]\n",
      " [ 0.49669788  0.32842351  0.          0.41364983  0.44772093  0.53090386]\n",
      " [ 0.63684059  0.65249574  0.41364983  0.          0.83721406  0.94935478]\n",
      " [ 0.56747494  0.28888665  0.44772093  0.83721406  0.          0.35078922]\n",
      " [ 0.49062729  0.38517657  0.53090386  0.94935478  0.35078922  0.        ]]\n",
      "\n",
      "Similar files are:\n",
      "\n",
      "data\\head_nod\\Gesture52_Session 20-Participant 39-Block 7_118670000_Skeleton.txt\n",
      "data\\head_nod\\Gesture52_Session 20-Participant 40-Block 1_1220811621_Skeleton.txt\n",
      "\n",
      "data\\head_nod\\Gesture52_Session 20-Participant 40-Block 1_1220811621_Skeleton.txt\n",
      "data\\arms_move_down\\Gesture968_Session 6-Participant 12-Block 3_56330000_Skeleton.txt\n",
      "\n",
      "data\\head_nod\\Gesture52_Session 18-Participant 36-Block 4_271330000_Skeleton.txt\n",
      "data\\head_nod\\Gesture52_Session 20-Participant 40-Block 1_1220811621_Skeleton.txt\n",
      "\n",
      "data\\arms_move_down\\Gesture968_Session 16-Participant 32-Block 3_1437000000_Skeleton.txt\n",
      "data\\head_nod\\Gesture52_Session 18-Participant 36-Block 4_271330000_Skeleton.txt\n",
      "\n",
      "data\\arms_move_down\\Gesture968_Session 6-Participant 12-Block 3_56330000_Skeleton.txt\n",
      "data\\head_nod\\Gesture52_Session 20-Participant 40-Block 1_1220811621_Skeleton.txt\n",
      "\n",
      "data\\arms_move_down\\Gesture968_Session 3-Participant 5-Block 8_827038820_Skeleton.txt\n",
      "data\\arms_move_down\\Gesture968_Session 6-Participant 12-Block 3_56330000_Skeleton.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dtw import dtw\n",
    "\n",
    "# Get a combined list of the skeleton files chosen earlier\n",
    "combined_files = x_files + y_files\n",
    "\n",
    "print(\"Samples chosen:\\n\")\n",
    "for i in combined_files:\n",
    "    print(i)\n",
    "    \n",
    "# Initializing the similarity matrix to be used for final comparison\n",
    "s_matrix = np.zeros( len(combined_files) ** 2).reshape(len(combined_files), len(combined_files))\n",
    "\n",
    "# Populating the similarity matrix with distance outputs from DTW\n",
    "for i, fi in enumerate(combined_files):\n",
    "    fi_data = load_skeleton_data(fi)\n",
    "    for j, fj in enumerate(combined_files):\n",
    "        fj_data = load_skeleton_data(fj)\n",
    "        dist, cost, acc, path = dtw(fi_data, fj_data, dist=lambda a, b: np.linalg.norm(a - b))\n",
    "        s_matrix[i, j] = dist\n",
    "print()\n",
    "\n",
    "print(\"Similarity matrix is:\\n\")\n",
    "print(s_matrix)\n",
    "print()\n",
    "\n",
    "s_matrix_c = np.copy(s_matrix)\n",
    "\n",
    "print(\"Similar files are:\\n\")\n",
    "for i in range(len(s_matrix_c)):\n",
    "    s_matrix_c[i,i] = float(\"inf\")\n",
    "    min_index = np.argmin(s_matrix_c[i])\n",
    "    print(combined_files[i])\n",
    "    print(combined_files[min_index])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_playlist(s_matrix, combined_files):\n",
    "    similar_playlist = open('similar.pls', 'w')\n",
    "    similar_playlist.write('[playlist]\\n\\n')\n",
    "    s_matrix_c = np.copy(s_matrix)\n",
    "    for i in range(len(s_matrix_c)):\n",
    "        s_matrix_c[i,i] = float(\"inf\")\n",
    "        min_index = np.argmin(s_matrix_c[i])\n",
    "        similar_playlist.write('File' + str(2*i + 1) + '=' + str(combined_files[i])[:-13] + '.avi\\n\\n')\n",
    "        similar_playlist.write('File' + str(2*i + 2) + '=' + str(combined_files[min_index])[:-13] + '.avi\\n\\n')\n",
    "    similar_playlist.write('NumberOfEntries=' + str(len(s_matrix)+1) + '\\n')\n",
    "    similar_playlist.write('Version=2')\n",
    "    similar_playlist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_playlist(s_matrix, combined_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [proposal]",
   "language": "python",
   "name": "Python [proposal]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
