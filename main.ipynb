{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Returns a copy of data which is normalized around mean of spinal base point\n",
    "def normalize_spine_base(data):\n",
    "    b = np.copy(data)\n",
    "    spine = np.zeros(3)\n",
    "    for i in range(3):\n",
    "       spine[i] = np.mean(b[:, i])\n",
    "    m, n = b.shape\n",
    "    for i in range(n):\n",
    "       b[:, i] -= spine[i % 3]\n",
    "    return b\n",
    "\n",
    "# Pulls up torso skeleton data from a general skeleton file, and normalizes it using normalize_spine_data()\n",
    "def load_skeleton_data(filename):\n",
    "    data = np.loadtxt(filename, dtype='float', delimiter=',', skiprows=1, usecols=(9, 10, 11, 18, 19, 20, 27, 28, 29, 36, 37, 38, 45, 46, 47, 54, 55, 56, 63, 64, 65, 72, 73, 74, 81, 82, 83, 90, 91, 92, 99, 100, 101, 108, 109, 110, 189, 190, 191))\n",
    "    return normalize_spine_base(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "from pathlib import Path\n",
    "\n",
    "# Chosse a random skeleton file for a given gesture\n",
    "def choose_random_skeleton(gesture):\n",
    "    current_dir = Path('.')\n",
    "    data_dir = current_dir / 'data' / 'clean' / gesture\n",
    "    return random.choice([str(f) for f in list(data_dir.glob(\"*.txt\")) if f.is_file()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of samples to be taken from each gesture class\n",
    "tot_samples = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taking tot_samples number of samples from both gesture classes\n",
    "x_files = [ choose_random_skeleton('head nod') for i in range(tot_samples) ]\n",
    "y_files = [ choose_random_skeleton('arms_move_down(with sound)') for i in range(tot_samples) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dtw import dtw\n",
    "\n",
    "# Generating a similarity matrix from two list of files with equal length\n",
    "def gen_sim_matrix(x_files, y_files):\n",
    "    # Get a combined list of the skeleton files chosen earlier\n",
    "    combined_files = x_files + y_files\n",
    "    # Initializing the similarity matrix to be used for final comparison\n",
    "    s_matrix = np.zeros( len(combined_files) ** 2).reshape(len(combined_files), len(combined_files))\n",
    "    # Populating the similarity matrix with distance outputs from DTW\n",
    "    for i, fi in enumerate(combined_files):\n",
    "        fi_data = load_skeleton_data(fi)\n",
    "        for j, fj in enumerate(combined_files):\n",
    "            fj_data = load_skeleton_data(fj)\n",
    "            dist, cost, acc, path = dtw(fi_data, fj_data, dist=lambda a, b: np.linalg.norm(a - b))\n",
    "            s_matrix[i, j] = dist\n",
    "    return s_matrix\n",
    "\n",
    "# Generates list of tuples of similar files skeletons\n",
    "def gen_sim_files(x_files, y_files, s_matrix):\n",
    "    sim_files = []\n",
    "    # Get a combined list of the skeleton files chosen earlier\n",
    "    combined_files = x_files + y_files\n",
    "    s_matrix_c = np.copy(s_matrix)\n",
    "    for i in range(len(s_matrix_c)):\n",
    "        # Need to do this so that 0 entries along the diagonal are not chosen as the minimum\n",
    "        s_matrix_c[i,i] = float(\"inf\")\n",
    "        min_index = np.argmin(s_matrix_c[i])\n",
    "        sim_files += [ (combined_files[i], combined_files[min_index])]\n",
    "    return sim_files\n",
    "\n",
    "# Writes a playlist based on the list of files it gets\n",
    "# Make sure that files is a list of valid string paths\n",
    "def write_playlist(files):\n",
    "    # Creating a playlist file\n",
    "    similar_playlist = open('similar.pls', 'w')\n",
    "    \n",
    "    # Header of the .pls format\n",
    "    similar_playlist.write('[playlist]\\n\\n')\n",
    "    \n",
    "    for i in range(len(files)):\n",
    "        similar_playlist.write('File' + str(i+1) + '=' + files[i] + '\\n\\n')\n",
    "    \n",
    "    # The footer for .pls format\n",
    "    similar_playlist.write('NumberOfEntries=' + str(len(files)) + '\\n')\n",
    "    similar_playlist.write('Version=2')\n",
    "    similar_playlist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples chosen:\n",
      "\n",
      "data\\clean\\head nod\\Gesture52_Session 2-Participant 4-Block 7_488353095_Skeleton.txt\n",
      "data\\clean\\head nod\\Gesture52_Session 20-Participant 39-Block 4_209500000_Skeleton.txt\n",
      "data\\clean\\head nod\\Gesture52_Session 7-Participant 13-Block 3_3343330000_Skeleton.txt\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 12-Participant 24-Block 4_50330000_Skeleton.txt\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 11-Participant 22-Block 9_579000000_Skeleton.txt\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 19-Participant 37-Block 10_396830000_Skeleton.txt\n",
      "\n",
      "Similarity matrix is:\n",
      "\n",
      "[[ 0.          0.62740312  0.43802527  0.60149566  0.37424059  0.62614471]\n",
      " [ 0.62740312  0.          0.4127773   0.33733901  0.41698144  0.28914833]\n",
      " [ 0.43802527  0.4127773   0.          0.4247916   0.30255806  0.26161308]\n",
      " [ 0.60149566  0.33733901  0.4247916   0.          0.40126931  0.29626767]\n",
      " [ 0.37424059  0.41698144  0.30255806  0.40126931  0.          0.34335876]\n",
      " [ 0.62614471  0.28914833  0.26161308  0.29626767  0.34335876  0.        ]]\n",
      "\n",
      "Similar files are:\n",
      "\n",
      "data\\clean\\head nod\\Gesture52_Session 2-Participant 4-Block 7_488353095_Skeleton.txt\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 11-Participant 22-Block 9_579000000_Skeleton.txt\n",
      "\n",
      "data\\clean\\head nod\\Gesture52_Session 20-Participant 39-Block 4_209500000_Skeleton.txt\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 19-Participant 37-Block 10_396830000_Skeleton.txt\n",
      "\n",
      "data\\clean\\head nod\\Gesture52_Session 7-Participant 13-Block 3_3343330000_Skeleton.txt\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 19-Participant 37-Block 10_396830000_Skeleton.txt\n",
      "\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 12-Participant 24-Block 4_50330000_Skeleton.txt\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 19-Participant 37-Block 10_396830000_Skeleton.txt\n",
      "\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 11-Participant 22-Block 9_579000000_Skeleton.txt\n",
      "data\\clean\\head nod\\Gesture52_Session 7-Participant 13-Block 3_3343330000_Skeleton.txt\n",
      "\n",
      "data\\clean\\arms_move_down(with sound)\\Gesture1278_Session 19-Participant 37-Block 10_396830000_Skeleton.txt\n",
      "data\\clean\\head nod\\Gesture52_Session 7-Participant 13-Block 3_3343330000_Skeleton.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples chosen:\\n\")\n",
    "for i in x_files + y_files:\n",
    "    print(i)\n",
    "\n",
    "print()\n",
    "print(\"Similarity matrix is:\\n\")\n",
    "s_matrix = gen_sim_matrix(x_files, y_files)\n",
    "print(s_matrix)\n",
    "print()\n",
    "\n",
    "s_files = gen_sim_files(x_files, y_files, s_matrix)\n",
    "print(\"Similar files are:\\n\")\n",
    "for i in s_files:\n",
    "    print(i[0])\n",
    "    print(i[1])\n",
    "    print()\n",
    "\n",
    "# Modifying s_files for use into a playlist\n",
    "# Writing playlist entries for similar files one after the other\n",
    "# Trimming '_skeleton.txt' from the end and appending '.avi' suitable for the .pls file        \n",
    "s_v_files = [ tp[i][:-13]+'.avi' for tp in s_files for i in range(len(tp)) ]\n",
    "\n",
    "# Writing a pls file\n",
    "write_playlist(s_v_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try HMMs below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [proposal]",
   "language": "python",
   "name": "Python [proposal]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
